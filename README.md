# Twitter Custommer Support - Apple - hdbscan templates
This repository holds the public dataset built during my thesis. 

In the interest of reproducibility and to further stimulate research on the topic, we've crafted this dataset with public content, that corresponds to customer support interactions and approximates the task at hand. To create this public dataset, we built on previous work [Hardalov et al. 2018](https://arxiv.org/abs/1809.00303), in which the authors handcrafted a customer support dataset for chatbots, from the public Customer Support on Twitter data that is available on [Kaggle](https://www.kaggle.com/thoughtvector/customer-support-on-twitter). We followed the same preprocessing, isolating the tweets related to Apple support and filtering out the noisy ones.  We nonetheless processed the datafurther, to attend the needs of our problem. Given the apparent use of templated responses, we started by filtering out all tweets beyond the first interaction, as these were context specific and less likely to include templated answers. For the remaining tweets, we clustered similar responses, hopefully sharing a template, and assumed the clusters to be the golden template identifiers for the tweets in the clusters. After  analysing  various  text  distances,  we  decided  to  capture  the  similarities  between  responsetweets leveraging a pre-trained model from the Sentence-Transformers library [Reimers et al., 2019](https://arxiv.org/abs/1908.10084) to produce sentence embeddings.  In order to aggregate the similar sentences,  we used HDBSCAN [Campello et al., 2013](https://link.springer.com/chapter/10.1007%2F978-3-642-37456-2_14) to produce clusters over the response embeddings.   Finally,  we removed all clusters containing less than 5 elements and selected, for each cluster, the response that is closest to the centroid, as the template.  From inspection of the produced data, HDBSCAN could provide better clusters than alternative methods, such as DBSCAN or k-means. We  split  all  datasets  into  3  partitions,  namely train, val,  and test.   The test split  is  composed  ofthe most recent customer interactions , simulating the real scenario, whilst the train and val splits are composed of the remaining examples on a 85/15 stratified split.
